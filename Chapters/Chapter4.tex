% Chapter Template

\chapter{Model architecture} % Main chapter title

\label{Chapter4} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Model structure}
The structure of the neural network is such that it contains some number $n$ of fully connected layers and batch normalization for each layer, along with regularization. All of these layers have the same number of units. The last layer has a dropout of 50\%. In addition to these layers there is one more output layer. This is simply a dense layer with 1 unit. A grid search was performed to determine the hyperparameters that minmize the loss. Hyperparameters are parameters that are set before the training begins\cite{hyperparameters_definition}. These hyperparameters include number of units in each layer, number of epochs to train for, number of layers, batch size, optimizer and penalty to enforce in the regularization. The possible combinations tried can be seen in Table \ref{table:gridSearchHyperparamters}.

\begin{table}[h]
    \centering
    \caption{Hyperparamter search with best performing combination colored red}
    \label{table:gridSearchHyperparamters}
    \begin{tabular}{c|c}
        Layers &  4, \textcolor{red}{5}, 6, 7, 8, 9\\\hline
        Units &  128, 256, 512\\\hline
        Epochs & 100, 200, 500\\\hline
        Batch size & 32, 64, 128, 256\\\hline
        Optimizers & Adam, RMSprop, Adamax\\\hline
        Penalties & 1, 0.1, 0.01, 0\\\hline
    \end{tabular}
\end{table}

\section{Feature selection and importance}
Using the three datasources, a model is trained. The data from IMO only represents the ground truth and is not used as part of the training data. The gust ($f_g$) and wind speed ($f$) are used to calculate the target gust factor. All weather parameters used in predictions come from the CARRA reanalysis data, with variables wind speed, wind direction, temperature, pressure. All of these variables are queried in three height levels (15, 250, 500 meters above ground) at the location of a given weather station. The second data source for the training data, is the elevation data. IMO provided a GeoTif file that contains elevation information above sea level, covering Iceland, in a 20 by 20 grid. A couple of different landscape distributions were looked at. A sector upwind, a sector upwind and downwind as well as a circle surrounding a weather station.

To add to these observed values and reanalysis, two derived variables, the Richardson number and the Brunt-V채is채l채 frequency, were calculated. To begin with all the available parameters were used to train the model along with the derived variables to see. This is done to be able to then use tools such as Shapley to see which features are impacting the predictions. Using Shapley values to see which features, will then enable the exclusion of features that don't affect the model prediction and simplify the training data. This means starting with much higher dimensionality of our training data and reduce it as much as possible without impacting our results. This crystallizes in the landscape points. Starting with $n$ points that describe the elevation of the landscape around our weather station. This $n$ might be in the hundreds. Looking at concentric circles outward from a given weather station, there might be 10 circles (largest with radius 20 km), each with 72 points (5째 spacing) and end up with 720 points for the landscape. This might slow down training. In addition, certain landscape features might be more important than others. There might be a large mountain up- or downwind of a given weather station, that might be the most important feature. To address this principal component analysis (PCA) is used to try to reduce the dimensionality of our landscape elevation data. PCA is a statistical procedure that allows the summarization of multivariate data to lower dimension and thus can ease visualization or increase speed of training a complex model with only minimal adverse effect to performance\cite{pca_information}. Another thing that might serve the same purpose is to select some number of $m$ points that have the most increase or decrease in elevation from the weather station along with the coordinates of those points in relation to the weather station and the direction of the wind.

Using all the variables from CARRA, along with the two derived factors ($Ri$, $N$) and two sectors (upwind and downwind) downscaled to 10 features using PCA, the feature importance can be seen in Figure \ref{fig:ShapleyWaterfallFirstTry}. The waterfall graph in Figure \ref{fig:ShapleyWaterfallFirstTry} shows that the Richardson number for higher levels is most important.

\begin{figure}[h]
    \caption{Feature importance of a neural network as described with 5 hidden layers and 256 units in each}
    \label{fig:ShapleyWaterfallFirstTry}
    \centering
    \includegraphics[scale = 0.6]{Figures/shap_bar_nn_256_example100.png}
\end{figure}