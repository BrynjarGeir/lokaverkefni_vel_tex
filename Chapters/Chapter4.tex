% Chapter Template

\chapter{Model architecture} % Main chapter title

\label{Chapter4} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Model structure}
The structure of the neural network is such that it contains some number $n$ of fully connected layers and batch normalization for each layer, along with regularization. All of these layers have the same number of units. The last layer has a dropout of 50\%. In addition to these layers there is one more output layer. This is simply a dense layer with 1 unit. A grid search was performed to determine the hyperparameters that minimize the loss. Hyperparameters are parameters that are set before the training begins\cite{hyperparameters_definition}. These hyperparameters include number of units in each layer, number of epochs to train for, number of layers, batch size, optimizer and penalty to enforce in the regularization. The possible combinations tried can be seen in Table \ref{table:gridSearchHyperparamters}.

\begin{table}[h]
    \centering
    \caption[Hyperparamter search with best performing combination.]{Hyperparamter search with best performing combination shown. Hyperparameter search was done using hyperband algorithm that initially searches randomly for the best parameters but then hones in on what is working and as such is neither exhaustive nor completely random. This means that an upper limit will not be set on the number of combinations to try like with randomsearch.}
    \label{table:gridSearchHyperparamters}
    \begin{tabular}{c|c|c}
        Parameter & Range of values & Selected\\\hline
        Layers &  min\_value = 4, max\_value = 15, step = 1 & \textbf{10}\\\hline
        Units &  min\_value = 32, max\_value = 512, step = 32 & \textbf{64}\\\hline
        Penalties & min\_value = 1e-5, max\_value = 1, sampling = log & \textbf{1e-4}\\\hline
        Epochs & min\_value = 10, max\_value = 1000, step = 10 & \textbf{30}\\\hline
        Optimizers & Adam, RMSprop, Adamax & \textbf{Adamax}\\\hline
        Activation & ReLU, ELu, Softmax & \textbf{ReLU}\\\hline
    \end{tabular}
\end{table}