\chapter{Results}
\label{Chapter4}
\section{Baseline models}
The simplest model for the gust factor is to guess the average gust factor for all available observations, i.e. use no variables from the training data. A slightly better model is obtained by using the wind speed as a training feature, either through regression or NN training. The MAPEs for the constructed base models are shown in Table \ref{table:baseline_models}. The ws$_{15}$ model was obtained with NN training but regression produces an almost identical result.

\begin{table}[h]
  \caption[MAPE for baseline models]{MAPE for several lower limits on the reanalysis 15 m wind speed ($ws_{15}$). Note that the ws$_{15}$ model was only evaluated for the 10 m/s lower bound.}
    \label{table:baseline_models}
    \centering
    \begin{tabular}{lcc}
        \toprule
        Wind speed & \multicolumn{2}{c}{MAPE}\\ 
        limit $[m/s]$ & mean model & ws$_{15}$ model\\
        \midrule
        $\geq 0$ & 39.2\%  & \\
        $\geq 5$ & 28.1\%  & \\
        $\geq 10$ & 23.9\% & 17.2\%\\
        $\geq 15$ & 23.2\% & \\
        $\geq 20$ & 24.7\% & \\
        $\geq 25$ & 27.7\% & \\
        \bottomrule
    \end{tabular}
\end{table}

As the average wind speed increases, then the variability in gust as a percentage decreases \cite{mean_gust_HA_HO}. Therefore lower MAPE would be expected if the training data is restricted to higher wind speeds. This fact explains why several models were created for different lower bounds.

\section{Modeling for ws$_{15}$ above 10 m/s}
As noted in Chapter \ref{Chapter1}, it is more important to predict accurate gust factor when it is windy than when the weather is calm. Therefore, at first, the data is restricted to ws$_{15} \geq 10$ m/s. The first constructed model incorporates the features temperature, pressure and wind direction at 15 m height. This gives a moderately reduced MAPE of 16.7\% compared with 17.2\% for the baseline ws$_{15}$ model. When the next pair of features, station altitude and transformed wind direction, is included, the MAPE is reduced considerably, down to 13.8\%. The atmospheric stability indicators, Ri and $N^2$, add little to the model performance, contrary to what might have been expected. When the atmosphere is unstable, wind gusts from higher up might be expected. However, another considerable performance increase is observed when digital elevation model (DEM) information is included, down to a MAPE of 12.0\%. This represents over 30\% reduction in the MAPE from the ws$_{15}$ baseline model.

The resulting model will be referred to as the \textit{primary model} and the corresponding parameters as the \textit{primary parameter set}. The .

\begin{table}[h]
  \caption[Model results for different sets of parameters.]{Models defined by a selection of parameter sets, with increasing complexity. The table shows decreasing MAPE as more variables are added.}
    \label{table:setsOfParams}
    \centering
    \begin{tabular}{lc}
        \toprule
        Model variables & MAPE\\
        \midrule
        $[\,]$ Baseline & 23.9\%\\
        $[ws_{15}]$ Baseline & 17.2\%\\
        $[ws_{15}, t_{15}, p_{15}, wd_{15}]$ & 16.7\% \\
        $[ws_{15}, t_{15}, p_{15}, wd_{15}, \text{altitude}, twd]$ & 13.8\% \\
        $[ws_{15}, t_{15}, p_{15}, wd_{15}, \text{altitude}, twd, N^2, Ri]$ & 13.7\%\\
        $[ws_{15}, t_{15}, p_{15}, wd_{15}, \text{altitude}, twd, N^2, Ri]$ + DEM* & 12.0\%\\
        $[ws_{15,250,500}, t_{15,250,500}, p_{15,250,500}, wd_{15,250,500}, \text{altitude}, twd, N^2, Ri]$ & 12.0\% \\
        \bottomrule
        *\small{Primary model}
    \end{tabular}
\end{table}

\section{Modeling for various ws$_\textbf{15}$ lower bounds}
To assess how model performance depends on ws$_{15}$ lower bound several models were trained using the variable sets in rows 5 and 6 in Table \ref{table:setsOfParams}, i.e. ws$_{15}$, $t_{15}$, $p_{15}$, wd$_{15}$, altitude, twd, $N^2$, Ri, as well as the same set together with DEM (the primary model). The results can be seen in Table \ref{table:results}. For this investigation comparison was only made with the constant baseline model. In all cases adding the DEM information is seen to increase the model performance. The reason for the difference between the 10 m/s lower bound results seen in Tables \ref{table:setsOfParams} and \ref{table:results} is they were obtained with different training setups. 

\begin{table}[h]
  \caption[Model results for different wind speed limits]{MAPE for each ws$_{15}$ lower bound without and with landscape elevation data (DEM) in a 30° sector into the direction of the reanalysis wind. Adding DEM data reduces the error noticably. Note that the MAPE is higher for both the lower lower bounds and for the higher ones.}
    \label{table:results}
    \centering
    \begin{tabular}{lccc}
        \toprule
        Wind Speed & \multicolumn{3}{c}{MAPE} \\
        limit $[m/s]$ & Baseline & Without DEM & With DEM \\
        \midrule
        $\geq 0$ & 39.2\% & 19.2\% & 18.9\% \\
        $\geq 5$ & 28.1\% & 15.3\% & 14.9\%\\
        $\geq 10$ & 23.9\% & 13.3\% & 12.5\%\\
        $\geq 15$ & 23.2\% & 14.4\% & 11.9\%\\
        $\geq 20$ & 24.7\% & 15.7\% & 13.3\%\\
        $\geq 25$ & 27.7\% & 19.4\% & 17.3\%\\
        \bottomrule
    \end{tabular}
  \end{table}

\section{Results for specific locations}
In this section, the distribution of MAPE by station will be considered. For each station the primary model MAPE was computed using just the ws$_{15} \geq 10$ data for that station was calculated and the results are shown in Figure (\ref{fig:errorMap}). The stations with low performance are all near mountains and often in fjords. The worst cases are in Vestfirðir and Austfirðir, and several bad stations are e.g. in Tröllaskagi and Snæfellsnes, and near Öræfajökull, Esja, Eyjafjallajökull. Inland stations seem to have lower error. The worst performing station is Seljalandsdalur in Vestfirðir while the best performing station is Garðskagaviti at the tip of the Reykjanes peninsula. Evidently rugged landscape makes it difficult to estimate the gust factor accurately.

\begin{figure}[h]
    \centering
    \includegraphics[scale = 0.5]{Figures/errorMap.png}
\caption[MAPE distribution by station]{Mean absolute percentage error (MAPE) at each station, shown as colored circles (dark blue = low error; yellow = high error). The lowest station error is about 7\% at Garðskagaviti and the highest about 35\% at Seljalandsdalur. The model uses a 10 m/s lower bound based on ws$_{15}$.}
\label{fig:errorMap}
\end{figure}

After examining the MAPE at each station individually, it is logical to try accounting for the station (or its location) in the model’s design. There are two ways to do this: To include the station location in the training data, and to train on subsets of the data, e.g. by station or groups of stations. Here the latter approach is considered. Results of an investigation for a few stations can be seen in Table \ref{table:specific_sites}. For many of the stations, the results are worse than expected, sometimes much worse, calling for further investigation.

\begin{table}[h]
  \caption[Model result by station]{MAPE for a few selected stations, for a model trained with the whole data set (general training), and for a model trained only with the data of the station itself (site training), with a lower bound of 10 m/s. This investigation was done in an earlier phase of the study, when $f$ instead of ws$_{15}$ was being used as the lower bound cut off, and that leads to some data leakage and a somewhat lower MAPE.}
    \label{table:specific_sites}
    \centering
    \begin{tabular}{lccc}
        \toprule
        Station name & n & \multicolumn{2}{c}{MAPE}\\
        & & General training & Site training\\
        \midrule
        Akrafjall & 43,000 & 18.6\% & 93.7\%\\
        Almannaskarð & 4,000 & 12.2\% & 86.7\%\\
        Ásgarðsfjall & 15,000 & 9.1\% & 9.4\%\\
        Jökulheimar & 17,000 & 7.7\% & 7.7\%\\
        Sandbúðir & 19,000 & 6.8\% & 6.4\%\\
        Stórholt & 35,000 & 7.1\% & 29.2\% \\
        Þúfuver & 20,000 & 6.4\% & 6.8\%\\
        \bottomrule
    \end{tabular}
\end{table}

\section{Results for wind speed intervals}
In addition to training for individual stations one can also try to train for individual wind speed intervals. Table \ref{table:closed_intervals} shows the results of training the primary model 

\begin{table}[h]
    \caption[Model result looking at closed wind speed intervals]{The MAPE results for different wind speed limit intervals. Here instead of training for all data above a certain threshold of wind speed, training is done only on data between two wind speeds. The percentage variance in gust factor as a function of wind speed increases with decreasing wind speed. Measured wind speed is used for the cutoff and thus have data leakage. These results should thus be somewhat comparable to the last column in Table (\ref{table:results})}
    \label{table:closed_intervals}
    \centering
    \begin{tabular}{lcc}
        \toprule
        Interval &  \multicolumn{2}{c}{MAPE}\\
        $[m/s]$ & Without Elevation & With Elevation\\
        \midrule
        $[5, 10[$ & 17.1\% & 16.4\%\\
        $[10, 15[$ & 14.5\% & 13.0\%\\
        $[15, 20[$ & 15.0\% & 12.0\%\\
        $[20, 25[$ & 15.6 \% & 13.1\%\\
        $[25, 30[$ & 18.4\% & 19.0\%\\
        \bottomrule
    \end{tabular}
\end{table}

Table (\ref{table:closed_intervals}) shows no improvement over the values in the last column in Table (\ref{table:results}). As previously mentioned, the gust factor decreases with increasing wind speed and thus, training on intervals and lessening this effect might be expected to give better results. This does not seem to be the case. Some interesting sites to look closer at for drivers might include places such as Ingólfsfjall, Kjalarnes and others. These can be seen in Table \ref{table:more_specific_sites}.

\begin{table}[h]
    \caption[Model result by stations of interest]{The MAPE results of different stations for several stations of interest, both when training for the specific site and when the stations are a part of the general data. For every station the wind speed limit is set at 10 m/s. In training for a single station at a time, some site specific information can be gauged. This does not mean that the a better result can be reached for that site. Factors such as the number of datapoints at given location can significantly impact the result. This table uses the measured wind speed to determine the cut off for data points. This leads to some data leakage and an increased performance compared to using the reanalysis CARRA speed for cut off.}
    \label{table:more_specific_sites}
    \centering
    \begin{tabular}{lcc}
        \toprule
        Station name & \multicolumn{2}{c}{MAPE}\\
         & Baseline & Model\\
        \midrule
        Fáskrúðsfjörður & 28.2\% & 21.8\%\\
        Ingólfsfjall & 30.0\% & 19.6\%\\
        Kjalarnes & 20.7\% & 13.5\% \\
        Sandskeið & 13.0\% & 10.2\%\\
        Seyðisfjörður & 32.1\% & 23.0\%\\
        Þjórsárdalur & 12.2\% & 11.4\%\\
        Þrengsli & 13.6\% & 11.3\%\\
        \bottomrule
    \end{tabular}
\end{table}

\section{Comparison for models with variable parameters}

In Figure (\ref{fig:ShapleySummary}) the contribution of each feature, excluding the elevation points, can be seen for the model in general (a significant subset of data is used). Looking at Figure (\ref{fig:ShapleySummary}), there is an outlier. Exactly calculating the Shapley values is time intensive, in the subset shown there is an outlier that skews the figure and makes it so that viewing the importance distribution excluding the outlier is difficult. For this reason, another shapley summary was created that looked at different, and larger distribution. This can be seen in Figure (\ref{fig:ShapleySummary2}). The Figures (\ref{fig:ShapleySummary}) and (\ref{fig:ShapleySummary2}) show the summary for a model trained only on the features shown and not on landscape elevation of the surrounding area. This is done as the number of points there is too high to display in one figure (70 total points). Looking specifically at Figure (\ref{fig:ShapleySummary2}), the station elevation is most influential and the Richardson number's influence is very low. Most of the feature values bunch up in the middle, while the station elevation is elongated compared to other features. Station elevation seems to have two bunches on either side of 0. Overall, the values seem to be skewed to the right of 0. This would be expected as the predicted values are expected to be in the range of 1.2-2, or at least always above 1 by definition. Finally, for the Shapley values, looking that all the data there are again outliers that skew the data so that spotting general distribution is difficult. This can be seen in Figure (\ref{fig:ShapleySummary3}).

\begin{figure}
    \centering
    \includegraphics[scale = 0.6]{Figures/shap_plots/summary_plot.png}
    \caption[Summary feature importance of a neural network.]{Feature importance of a neural network with model architecture as described in Table \ref{table:gridSearchHyperparameters} and data as described in Table \ref{table:trainDataExample}. We can see that generally multiple factors influence the prediction, with the station elevation being highly influential. There is seemingly one outlier for the Richardson number, which usually has very little influence. Elevation data is excluded when working with Shapley values, as the contribution of each elevation point is very low and there are very many of them. To see their influence on the model output see Table \ref{table:results}.}
    \label{fig:ShapleySummary}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale = 0.6]{Figures/shap_plots/summary_plot_190924_.png}
    \caption[Summary feature importance of a neural network using a larger distribution of data.]{Feature importance of a neural network with model architecture as described in Table \ref{table:gridSearchHyperparameters} and data as described in Table \ref{table:trainDataExample}. Generally multiple factors influence the prediction, with the station elevation being highly influential. Elevation data is excluded when working with Shapley values, as the contribution of each elevation. In contrast to Figure (\ref{fig:ShapleySummary}), the distribution doesn't have as extreme outliers. This means that more details can be seen in the figure. The X-axis shows the influence of feature values on the model. The color gradient shows the value of each feature. As an example, there is a very red value for station elevation (top line, all the way to the left). This means that in this instance, the station elevation contributed around -0.25 to the final output and that the station had an elevation significantly above average.}
    \label{fig:ShapleySummary2}
\end{figure}

Further Shapley figures can be seen in Appendix~\ref{appendix:A}. In each of these plots, even without the feature labels, the station elevation is easily noticed as the value is constant for a station. This is not noteworthy. What is noteworthy is the range of impact from this single value. For simpler models, this would not happen. It is important to note that SHAP assumes feature independence \cite{Salih_2024}. This might explain why the impact of the Richardson number is so low. Both the squared Brunt–Väisälä frequency and the Richardson number are derived features from reanalysis data. They carry with them some extra information over the other features in the dataset. This is because both are variables over elevation ranges. That is, as seen in Equations (\ref{eqn:Ri}, \ref{eqn:N}), both are dependent on values at lower and upper elevations and try to describe the stability of that range. Shapley tries to assign contribution values for each feature for each observation. SHAP assumes that the features are independent, but this is not the case. It is clearly not the case for the derived variables, but how the contribution should be distributed between the features is not clear. Seemingly the SHAP python package is giving all the impact to the Brunt–Väisälä squared frequency and none to Richardson number. If the Brunt–Väisälä would be excluded from the data, the impact of the Richardson number would likely increase. Another point to note is that the features are ordered by their impact. This means that the station elevation is the most impactful for each plot, but the ordering of other variables changes. Looking at Figure (\ref{fig:ShapleySummary3}), which shows the Shapley summary plot for all data, the wind speed is the second most important feature. This is reversed in Figure (\ref{fig:ShapleySummaryAkrafjall}). This is not unexpected as Akrafjall station was specifically selected as the MAE for reanalysis wind speed was very high as can be seen in Table (\ref{fig:ShapleySummaryAkrafjall}), where you will also find the stations whose summary plot is shown in Figures (\ref{fig:ShapleySummaryAlmannaskarð}, \ref{fig:ShapleySummaryAsgarðsfjall}) and these also fall into the category of very high MAE for wind speed. What is interesting is that the reanalysis wind speed is also of low impact at stations like Háahlíð and Keflavíkurflugvöllur, as shown in Figures (\ref{fig:ShapleySummaryHaahlid}, \ref{fig:ShapleySummaryKeflavikurflugvollur}). These stations had the lowest of MAE for difference between measured wind speed and reanalysis wind speed. As the summary plot over all stations (Figure (\ref{fig:ShapleySummary3})) shows that reanalysis wind speed is impactful, might lead to the conclusion that the reanalysis wind speed is not a good predictor at these locations or something else is skewing the data. A simpler way to look at feature importance is to create models that are trained on and use to predict different sets of parameters. The results of such a comparison can be seen in Table \ref{table:setsOfParams}.

