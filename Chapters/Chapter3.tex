\chapter{Data processing and structure}
\label{Chapter3} 
\section{Combining data sources}

This project used three main data sources, which need to be queried, filtered and combined to prepare the data for use in the models. When working with hundred of thousands of rows, the efficiency of the code is very important. Iterating through those rows might be necessary at times but will increase the time exponentially as compared to using vectorizing methods were possible. The three data sources were all in a different format. Measurement data from IMO was in text files, elevation data was in GeoTiff and reanalysis data from CARRA was in a GRIB format. To use the data to train, these three data sources needed to be combined into one file. This was done based on the measurement data from the IMO. A limit was set on the average wind speed and it was used to select measurement points. Along with the average wind speed having to be above a certain limit, to ensure that the same weather for the same location is not duplicated. The data from IMO was supplied for 10 minute increments, while CARRA data is in 3 hour intervals. This means that to use the CARRA data to predict the measured values from IMO, temporal interpolation would need to be done. Along with the temporal interpolation, note that the CARRA data is given in a rectangular grid where the distance between each point is around 2.5 km while the the information from the IMO is given at specific locations. The elevation information was given by a 20 by 20 rectangular grid that covers Iceland. When combining these data sources an interpolation method needs to be decided upon. Here linear interpolation was applied, both temporally and spatially. The choice of interpolation method, although potentially impactful on the results, was not specifically addressed in this study.

\begin{figure}[h]
    \includegraphics[scale = 0.5]{Figures/data-preprocessing-flow-chart.png}
    \caption{A flow chart showing how data sources were combined}
    \label{fig:data_preprocessing_flow_chart}
\end{figure}

The procedure of combining these sources was as follows and can be seen in Figure \ref{fig:data_preprocessing_flow_chart}. The measured data from the AWS is filtered by using a limit on the average wind speed. The gust factor generally drops with increased wind speed (although not always dependent on factors such as the landscape \cite{GNP_vidtal}). Even so being able to predict the gust factor is more important for higher average wind speed due to higher wind gusts. After this stripped dataset over every AWS has been created it is used to query the CARRA data by using their API. The CARRA API needs to be queried for given hours, days, months, years and a given area. That is, if queried for a given hour, it returns that hour for every day that is queried. Similarly if queried for a given day, it returns that day for every month. In light of these restraints, it was decided to query month by month. Querying only the days needed but every hour of the day (UTC 00, 03, 06, 09, 12, 15, 18 and 21). After querying and downloading the data for the height levels and variables requested, points of interest are interpolated and values stored in a pandas dataframe. After this the downloaded data is discarded and the next month is queried. This drastically decreases the amount of data that needs to be stored as compared to downloading the entire area and keeping all the data points (a reduction from several terabytes to less than a gigabyte).

Once CARRA data has been merged with AWS data, using station and time columns, then this combined file needs to checked for nails. This is done by using the hourly data (which is supposedly error free). As the data has been filtered in for the highest average wind speed in a 48 hour interval, the hourly data can be used to find nails. The hourly data is combined with the merged AWS and 10 min data. Then filtering is applied on the average wind. If the average wind speed differs the rows are dropped.

After filtering out nails, most stations have nails in less that 10\% measurements. The stations that have higher than 10\% error are ignored.

The elevation data comes in a GeoTIFF file that covers Iceland. It is a rectangular grid of resolution 20 meters. For every point of interest (every weather station), the elevation of that given point along with other points surrounding the weather station is retrieved. For each point retrieved interpolation needs to be done. This is done in a similar manner to the interpolation of the CARRA data. The four points bounding the point of interest were used to linearly interpolate the value of the point of interest. This information is included in the training data as the landscape is known to influence both the average wind and the gustiness \cite{GNP_vidtal}.

The error in reanalysis wind speed and measured wind speed can be significant. The absolute error increases as the measured wind speed increases, while the percentage wind speed decreases. A grouping of these errors by wind speed can be seen in Table \ref{table:measuredVSReanalysis_wind_speed}


\begin{table}[h]
    \caption[Comparison of measured and reanalysis wind speed]{Comparison of measured and reanalysis wind speed using mean absolute error (MAE) and mean absolute percentage error (MAPE). Note that for the computation of MAPE for ranges that otherwise include 0, 0 values have been excluded so as to prevent division by zero and exploding values. The comparisons are done using measured wind speed (at 10 meters above ground for IMO and 6-7 meters above ground for IRCA) and reanalysis wind speed at 15 meters above ground.}
    \label{table:measuredVSReanalysis_wind_speed}
    \centering
    \begin{tabular}{cccc}
        
        f & n & MAE & MAPE \\
        
        {[}0;5{[} & 6.2e6 & 2.1 & 1.6\\
        {[}5;10{[} & 4.2e6 & 2.2 & 0.3\\
        {[}10;15{[} & 1.5e6 & 2.5 & 0.2\\
        {[}15;20{[} & 3.9e5 & 3.0 & 0.2\\
        {[}20;25{[} & 8.4e4 & 4.0 & 0.2\\
        {[}25;$\infty${[} & 2.0e4 & 6.6 & 0.2\\
        {[}0;$\infty${[} & 1.2e7 & 2.2 & 1.0\\
        
    \end{tabular}
\end{table}

Another thing to look at is the distribution of error by station, both in terms of their coordinates and number of measurements. Looking at Figure \ref{fig:station_mae_distribution}, this distribution can be seen.

\begin{figure}
    \includegraphics[scale=0.6]{Figures/MAEoverIceland.png}
    \caption[Distribution of mean absolute errors by station]{The distribution of mean absolute errors by station. Using mean absolute error instead of mean absolute percentage error allows for all points to be used. Mean absolute percentage error can only be used if 0 values are ignored.}
    \label{fig:station_mae_distribution}
\end{figure}

Table \ref{table:station_mae_distribution} shows the 5 best and worst stations in terms of MAE.

\begin{table}[h]
    \caption[Mean absolute difference of measured wind speed and reanalysis wind speed at select stations]{Mean absolute error for reanalysis wind speed as compared to measured wind speed, for the five stations with the highest difference and the five stations with the lowest difference.}
    \label{table:station_mae_distribution}
    \resizebox{\textwidth}{!}{
    \centering
    \begin{tabular}{cccc}
        
        Station & Number of measurements & MAE & Location \\
        
        1470 & 6.8e3 & 1.17 & Reykjavík Háahlíð \\
        1350 & 5.2e4 & 1.18 & Keflavíkurflugvöllur \\
        1482 & 1.4e4 & 1.23 & Reykjavík Víðidalur \\
        4921 & 1.3e4 & 1.29 & Rif á Melrakkasléttu \\
        1477 & 5.6e4 & 1.29 & Reykjavíkurflugvöllur\\ \hdashline[0.5pt/1pt]
        35553 & 4.0e3 & 4.30 & Almannaskarð - göng\\
        6745 & 1.5e4 & 4.36 & Kerlingarfjöll - Ásgarðsfjall\\
        35978 & 7.9e3 & 4.40 & Fáskrúðsfjarðargöng suður\\
        2640 & 1.6e3 & 4.51 & Seljalandsdalur\\
        32635 & 3.2e4 & 4.95 & Botn í Súgandafirði\\
        
    \end{tabular}
    }
\end{table}

If the 0 m/s is excluded from the measurement data, then the error distribution using MAPE can be plotted. This plot can be seen in Figure \ref{fig:station_mape_distribution}

\begin{figure}
    \includegraphics[scale=0.6]{Figures/MAPEoverIceland.png}
    \caption[Distribution of MAPE by station]{The distribution of MAPE. Using MAPE instead of MAE, necessitates the exclusion of 0 values from the ground truth (measured values).}
    \label{fig:station_mape_distribution}
\end{figure}

\section{Data Structure}

Once data has been retrieved for all three sources and processed, including interpolating values, it needs to be made ready to use by the model, for both training, validation and test. The starting point is a dataframe that contains measured information from AWS. This includes the average wind, the wind gust, wind direction along with the station number and coordinates. When selecting the CARRA data certain height levels are chosen. These present as separate lines in the CARRA dataframe. Information for one observation is represented in as many lines as height levels requested in the reanalysis data. These rows need to be combined on the position (the weather station). When this is done it is possible to combine the AWS IMO data and CARRA reanalysis data on the location and time columns. The last data source is the elevation. A sector of a circle looking upwind is looked at. In any case the points, that represent these sections, were selected as shown in Code Listing \ref{code:sectorElevation}. A range of angles are defined based on the wind direction $d$ at some distance from the given point. This means that the resultant points (equal in number to the length of angleRange by k) form sectors at several distances from the given weather station.

\begin{lstlisting}[style = Python, caption = {Sector elevation points generated}, label = code:sectorElevation]
angles = [(angle + (90 - d)) * pi/180 for angle in angleRange]
length_rng = [(exp(i * log(n + 1)/ k) - 1) * 1000 
                for i in range(1, k + 1)]
points = np.array([[(X + l * cos(angle), Y + l * sin(angle))
                    for angle in angles] for l in length_rng])   
\end{lstlisting}

The result is a dataframe that has measured data from AWS, which gives us our target, reanalysis data from CARRA, which gives us weather variables to train on, and finally elevation points in the landscape to include in our training data. An example of what the data looks like can be seen in Table \ref{table:trainDataExample}.

\begin{table}[h]
    \caption[An example of data structure used to train model]{An example of data structure used to train model. Data points include the derived variables Ri and N, the elevation of the station, direction of wind and relative direction of the wind (twd, that is the direction of the wind relative to center of Iceland), along with some combination of wind speed, pressure and temperature at the different height levels. Finally there are the elevation points around a given station, where the elevation is relative to the station.}
    \label{table:trainDataExample}
    \resizebox{\textwidth}{!}{
    \centering
    \begin{tabular}{c|c|c|c|c|c|c|c|c|c}
         Ri & N\_squared & station\_elevation & twd & ws\_15 & wd\_15 & t\_15 & p\_15 & elevation\_point\_0 & \dots\\\hline
         -1.18e+00 &  2.67e+04 & 100 & 1.5 & 10 & 5 & 0 & 100 & 2 & \dots 
    \end{tabular}
    }
\end{table}

 Looking at Table \ref{table:trainDataExample} note that the first two columns represent two variables that describe the stability of the air. These are the Richardson number ($Ri$)\cite{richardson_number_skybrary} and Brunt–Väisälä frequency\cite{brunt_vaisala_freq_eumtrain} ($N$), and are calculated using Equations (\ref{eqn:Ri}) and (\ref{eqn:N})\cite{mean_gust_HA_HO}. These values are calculated using reanalysis data at two different height levels. Thus $Ri$ refers to the Richardson number calculated between height levels 15m and 500m. Exactly the same notation is used with the Brunt–Väisälä frequency, except the square is used.
\begin{equation}
    \label{eqn:Ri}
    Ri = \frac{g \cdot dT \cdot dz}{T_{\textrm ave} \cdot dU^2} \unit{[]}
\end{equation}

\begin{equation}
    \label{eqn:N}
    N = \sqrt{\frac{g \cdot dT }{T_{\textrm ave} \cdot dz}} \unit{[Hz]}
\end{equation}

Here, $g$ is the acceleration due to gravity, $dT$ is the temperature difference between the two height levels, $dz$ is the elevation difference, $T_{\textrm ave}$ is the average temperature (that is the average of the two temperatures in the height levels) and $dU$ is the wind speed difference between the two height levels. Both of these numbers provide some insight about the stability of the air. A lower value for the Richardson number indicates a higher turbulence. A typical range of values could be between 0.1 and 10, with values below 1 indicating significant turbulence\cite{richardson_number_skybrary}. When the square of the Brunt-Väisälä frequency is negative, then the air is unstable (an air parcel will move away from its original position)\cite{brunt_vaisala_freq_eumtrain}. These are derived factors from the reanalysis data and as such there shouldn't be a significant information gain using $Ri$ and $N$ as opposed to having the raw data. However, including these factors instead of every reanalysis variable requested might speed up training as well as making the model more easily explainable with the use of Shapley values or other tools for explainability. Using Shapley a feature importance value is attributed to a given feature by creating all possible permutations of any possible length (up to number of features) and seeing how the predictions are skewed when the given parameter is included or excluded. This needs to be done for all parameters. The time complexity of this is very high ($2^n$ coalitions)\cite{shapley_information}. Most implementations use some approximations, which still can take a considerable amount of time for models with a high parameter count and many examples.